{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11879 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "371/371 [==============================] - 435s 1s/step - loss: 0.4864 - accuracy: 0.7656 - val_loss: 0.4459 - val_accuracy: 0.7777\n",
      "Epoch 2/20\n",
      "371/371 [==============================] - 326s 877ms/step - loss: 0.4008 - accuracy: 0.8227 - val_loss: 0.3605 - val_accuracy: 0.8584\n",
      "Epoch 3/20\n",
      "371/371 [==============================] - 316s 850ms/step - loss: 0.3747 - accuracy: 0.8330 - val_loss: 0.3943 - val_accuracy: 0.8180\n",
      "Epoch 4/20\n",
      "371/371 [==============================] - 318s 858ms/step - loss: 0.3683 - accuracy: 0.8399 - val_loss: 0.2872 - val_accuracy: 0.8931\n",
      "Epoch 5/20\n",
      "371/371 [==============================] - 326s 879ms/step - loss: 0.3532 - accuracy: 0.8448 - val_loss: 0.3869 - val_accuracy: 0.8145\n",
      "Epoch 6/20\n",
      "371/371 [==============================] - 346s 931ms/step - loss: 0.3422 - accuracy: 0.8519 - val_loss: 0.3139 - val_accuracy: 0.8921\n",
      "Epoch 7/20\n",
      "371/371 [==============================] - 336s 906ms/step - loss: 0.3326 - accuracy: 0.8550 - val_loss: 0.2728 - val_accuracy: 0.9022\n",
      "Epoch 8/20\n",
      "371/371 [==============================] - 323s 869ms/step - loss: 0.3229 - accuracy: 0.8617 - val_loss: 0.2800 - val_accuracy: 0.8977\n",
      "Epoch 9/20\n",
      "371/371 [==============================] - 326s 878ms/step - loss: 0.3151 - accuracy: 0.8624 - val_loss: 0.3176 - val_accuracy: 0.8750\n",
      "Epoch 10/20\n",
      "371/371 [==============================] - 319s 859ms/step - loss: 0.3110 - accuracy: 0.8681 - val_loss: 0.3114 - val_accuracy: 0.8780\n",
      "Epoch 11/20\n",
      "371/371 [==============================] - 332s 895ms/step - loss: 0.3144 - accuracy: 0.8671 - val_loss: 0.3084 - val_accuracy: 0.8669\n",
      "Epoch 12/20\n",
      "371/371 [==============================] - 325s 874ms/step - loss: 0.3006 - accuracy: 0.8736 - val_loss: 0.2978 - val_accuracy: 0.8866\n",
      "Epoch 13/20\n",
      "371/371 [==============================] - 320s 861ms/step - loss: 0.3120 - accuracy: 0.8693 - val_loss: 0.3399 - val_accuracy: 0.8503\n",
      "Epoch 14/20\n",
      "371/371 [==============================] - 301s 811ms/step - loss: 0.3018 - accuracy: 0.8732 - val_loss: 0.2627 - val_accuracy: 0.9158\n",
      "Epoch 15/20\n",
      "371/371 [==============================] - 322s 868ms/step - loss: 0.2855 - accuracy: 0.8774 - val_loss: 0.2799 - val_accuracy: 0.8901\n",
      "Epoch 16/20\n",
      "371/371 [==============================] - 323s 870ms/step - loss: 0.2905 - accuracy: 0.8800 - val_loss: 0.3878 - val_accuracy: 0.8301\n",
      "Epoch 17/20\n",
      "371/371 [==============================] - 379s 1s/step - loss: 0.2920 - accuracy: 0.8761 - val_loss: 0.3009 - val_accuracy: 0.8942\n",
      "Epoch 18/20\n",
      "371/371 [==============================] - 392s 1s/step - loss: 0.2887 - accuracy: 0.8776 - val_loss: 0.4326 - val_accuracy: 0.7933\n",
      "Epoch 19/20\n",
      "371/371 [==============================] - 413s 1s/step - loss: 0.2841 - accuracy: 0.8768 - val_loss: 0.2865 - val_accuracy: 0.8866\n",
      "Epoch 20/20\n",
      "371/371 [==============================] - 409s 1s/step - loss: 0.2878 - accuracy: 0.8763 - val_loss: 0.3464 - val_accuracy: 0.8347\n",
      "63/63 [==============================] - 10s 163ms/step - loss: 0.3450 - accuracy: 0.8350\n",
      "Test accuracy: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\anaconda3\\envs\\compgraphics\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from PIL import Image \n",
    "import scipy\n",
    "# Define directories\n",
    "train_dir = \"C:/Users/ADMIN/Desktop/train\"\n",
    "test_dir = \"C:/Users/ADMIN/Desktop/test\"\n",
    "\n",
    "# Data Augmentation and Preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "# Model Building\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Model Training\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=test_generator.samples // test_generator.batch_size,\n",
    "    epochs=20\n",
    ")\n",
    "\n",
    "# Model Evaluation\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print(f'Test accuracy: {test_acc:.2f}')\n",
    "\n",
    "# Save the model\n",
    "model.save('cancer_classification_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('cancer_prediction_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 100ms/step\n",
      "The image is predicted to be: benign\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import numpy as np\n",
    "\n",
    "# Load the saved model\n",
    "model = tf.keras.models.load_model('cancer_prediction_model.keras')\n",
    "\n",
    "# Function to preprocess the image\n",
    "def preprocess_image(image_path):\n",
    "    img = load_img(image_path, target_size=(150, 150))  # Resize the image to 150x150 pixels\n",
    "    img_array = img_to_array(img)  # Convert the image to a numpy array\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add an extra dimension for batch size\n",
    "    img_array /= 255.0  # Scale the pixel values to [0, 1]\n",
    "    return img_array\n",
    "\n",
    "# Function to predict the class of the image\n",
    "def predict_image(image_path):\n",
    "    processed_image = preprocess_image(image_path)\n",
    "    prediction = model.predict(processed_image)\n",
    "    class_label = 'malignant' if prediction[0][0] > 0.5 else 'benign'\n",
    "    return class_label\n",
    "\n",
    "# Test the function\n",
    "image_path = \"C:/Users/ADMIN/Pictures/Screenshots/Screenshot 2024-07-03 232757.png\"\n",
    "result = predict_image(image_path)\n",
    "print(f'The image is predicted to be: {result}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
